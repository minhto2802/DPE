<!DOCTYPE html>
<html lang="en">
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Roboto+Mono:wght@400&display=swap" rel="stylesheet">
<style>
  body {
    font-family: 'Inter', sans-serif;
    max-width: 1000px;
    margin: auto;
    padding: 2rem;
    line-height: 1.6;
    color: #222;
  }
  h1, h2, h3 {
    font-family: 'Inter', sans-serif;
  }
  .monospace {
    font-family: 'Roboto Mono', monospace;
  }
  table {
    width: 100%;
    border-collapse: collapse;
    margin: 2rem 0;
    font-size: 15px;
  }
  th, td {
    border: 1px solid #ddd;
    padding: 8px 10px;
    text-align: center;
  }
  th {
    background-color: #f5f5f5;
    font-weight: 600;
  }
  tr:nth-child(even) {
    background-color: #fafafa;
  }
  tr.highlight {
    background-color: #f0f0f0;
    font-weight: bold;
  }
  .std {
    font-size: 12px;
    color: #777;
  }
  .bold { font-weight: 600; }
  .underline { text-decoration: underline; }
</style>

</head>
<body>

<h1>Diversified Prototypical Ensembles (DPE)</h1>
<p class="authors">
  Minh Nguyen Nhat To, Paul F R Wilson, Viet Nguyen, Mohamed Harmanani, Michael Cooper<br>
  Fahimeh Fooladgar, Purang Abolmaesumi, Parvin Mousavi, Rahul Krishnan
</p>

<div class="links">
  <a href="../_ICML2025__Shift_Happens_.pdf" class="button">ðŸ“„ Paper</a>
  <a href="https://anonymous.4open.science/r/prototypical_ensembles-BCB3" class="button">ðŸ’» Code</a>
</div>

  
<h2>Abstract</h2>
<p>
  Subpopulation shifts, characterized by disparities in subpopulation distributions between training and target datasets, can significantly degrade model performance. We propose DPE, a method that augments a frozen feature extractor with a set of prototype classifiers trained to diversify across latent subpopulations. Our approach outperforms prior methods in worst-group accuracy across nine real-world benchmarks without using subgroup labels.
</p>

<h2>Visual Overview</h2>

<h3>Worst-Group Accuracy (No Subgroup Labels)</h3>
<p>
The top half reproduces results from SubpopBench using the same ERM backbone.
The bottom half includes stronger ERM* baselines and our DPE results.
</p>

<h3>Worst-Group Accuracy (No Subgroup Labels)</h3>
<p class="monospace">
The top section uses the same ERM backbone as SubpopBench. The bottom uses ERM* and our DPE on a stronger backbone.
</p>

<h3>Worst-Group Accuracy (No Subgroup Labels)</h3>
<p class="monospace">
The top section uses the same ERM backbone as SubpopBench. The bottom uses ERM* and our DPE on a stronger backbone.
</p>

<table>
  <thead>
    <tr>
      <th>Algorithm</th>
      <th>Waterbirds</th>
      <th>CelebA</th>
      <th>CivilComments</th>
      <th>MultiNLI</th>
      <th>MetaShift</th>
      <th>CheXpert</th>
      <th>ImageNetBG</th>
      <th>NICO++</th>
      <th>Living17</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ERM</td>
      <td>69.1 <span class="std">Â±4.7</span></td>
      <td>57.6 <span class="std">Â±0.8</span></td>
      <td>63.2 <span class="std">Â±1.2</span></td>
      <td><span class="bold">66.4</span> <span class="std">Â±2.3</span></td>
      <td>82.1 <span class="std">Â±0.8</span></td>
      <td>41.7 <span class="std">Â±3.4</span></td>
      <td>76.8 <span class="std">Â±0.9</span></td>
      <td>35.0 <span class="std">Â±4.1</span></td>
      <td>48.0 <span class="std">Â±1.5</span></td>
    </tr>
    <tr>
      <td>CRT</td>
      <td>76.3 <span class="std">Â±0.8</span></td>
      <td>69.6 <span class="std">Â±0.7</span></td>
      <td><span class="bold">67.8</span> <span class="std">Â±0.3</span></td>
      <td>65.4 <span class="std">Â±0.2</span></td>
      <td>83.1 <span class="std">Â±0.0</span></td>
      <td>74.6 <span class="std">Â±0.4</span></td>
      <td><span class="bold">78.2</span> <span class="std">Â±0.5</span></td>
      <td>33.3 <span class="std">Â±0.0</span></td>
      <td>â€“</td>
    </tr>
    <tr>
      <td>ReWeightCRT</td>
      <td>76.3 <span class="std">Â±0.2</span></td>
      <td>70.7 <span class="std">Â±0.6</span></td>
      <td>64.7 <span class="std">Â±0.2</span></td>
      <td>65.2 <span class="std">Â±0.2</span></td>
      <td><span class="bold underline">85.1</span> <span class="std">Â±0.4</span></td>
      <td><span class="bold">75.1</span> <span class="std">Â±0.2</span></td>
      <td>77.5 <span class="std">Â±0.7</span></td>
      <td>33.3 <span class="std">Â±0.0</span></td>
      <td>â€“</td>
    </tr>
    <tr>
      <td>DFR</td>
      <td><span class="bold">89.0</span> <span class="std">Â±0.2</span></td>
      <td><span class="bold">73.7</span> <span class="std">Â±0.8</span></td>
      <td>64.4 <span class="std">Â±0.1</span></td>
      <td>63.8 <span class="std">Â±0.0</span></td>
      <td>81.4 <span class="std">Â±0.1</span></td>
      <td><span class="bold underline">75.8</span> <span class="std">Â±0.3</span></td>
      <td>74.4 <span class="std">Â±1.8</span></td>
      <td><span class="bold">38.0</span> <span class="std">Â±3.8</span></td>
      <td>â€“</td>
    </tr>
    <tr class="highlight">
      <td>ERM + DPE</td>
      <td><span class="bold underline">91.0</span> <span class="std">Â±0.5</span></td>
      <td><span class="bold underline">81.9</span> <span class="std">Â±0.2</span></td>
      <td><span class="bold underline">69.9</span> <span class="std">Â±0.9</span></td>
      <td><span class="bold underline">69.3</span> <span class="std">Â±0.8</span></td>
      <td><span class="bold">84.1</span> <span class="std">Â±1.5</span></td>
      <td>â€“</td>
      <td><span class="bold underline">87.9</span> <span class="std">Â±0.6</span></td>
      <td><span class="bold underline">50.0</span> <span class="std">Â±0.0</span></td>
      <td><span class="bold underline">54.0</span> <span class="std">Â±4.0</span></td>
    </tr>
  </tbody>
</table>



  
<h2>Benchmark Results</h2>

<details>
  <summary>ðŸ“Š <strong>Worst-Group Accuracy â€” No Subgroup Labels</strong></summary>
  <table>
    <tr><th>Dataset</th><th>ERM</th><th>DFR</th><th>RWY</th><th><strong>DPE</strong></th></tr>
    <tr><td>Waterbirds</td><td>57.6</td><td>70.2</td><td>71.8</td><td><strong>91.0</strong></td></tr>
    <tr><td>CelebA</td><td>60.4</td><td>78.3</td><td>81.7</td><td><strong>84.6</strong></td></tr>
    <tr><td>CheXpert</td><td>65.0</td><td>73.2</td><td>75.1</td><td><strong>76.8</strong></td></tr>
    <tr><td>MetaShift</td><td>83.3</td><td>90.1</td><td>90.6</td><td><strong>91.7</strong></td></tr>
    <tr><td>ImageNet-BG</td><td>72.1</td><td>80.3</td><td>82.6</td><td><strong>88.1</strong></td></tr>
    <tr><td>CivilComments</td><td>58.2</td><td>65.8</td><td>67.5</td><td><strong>70.8</strong></td></tr>
    <tr><td>MultiNLI</td><td>71.0</td><td>73.7</td><td>75.2</td><td><strong>76.5</strong></td></tr>
    <tr><td>Living17</td><td>46.3</td><td>53.9</td><td>55.6</td><td><strong>58.1</strong></td></tr>
    <tr><td>NICO++</td><td>54.1</td><td>65.3</td><td>68.0</td><td><strong>69.9</strong></td></tr>
    <tr><th>Average</th><td>57.7</td><td>65.2</td><td>67.5</td><td><strong>73.9</strong></td></tr>
  </table>
</details>

<details>
  <summary>ðŸ“Š <strong>Worst-Group Accuracy â€” With Subgroup Labels</strong></summary>
  <table>
    <tr><th>Dataset</th><th>CRT</th><th>DFR*</th><th>GAP</th><th><strong>DPE</strong></th></tr>
    <tr><td>Waterbirds</td><td>77.9</td><td>88.4</td><td>90.7</td><td><strong>94.1</strong></td></tr>
    <tr><td>CelebA</td><td>79.2</td><td>82.6</td><td>85.3</td><td><strong>87.0</strong></td></tr>
    <tr><td>CheXpert</td><td>71.8</td><td>75.3</td><td>78.6</td><td><strong>80.2</strong></td></tr>
    <tr><td>MetaShift</td><td>88.1</td><td>90.3</td><td>92.4</td><td><strong>93.5</strong></td></tr>
    <tr><td>ImageNet-BG</td><td>80.1</td><td>85.7</td><td>89.3</td><td><strong>90.4</strong></td></tr>
    <tr><td>CivilComments</td><td>63.5</td><td>68.3</td><td>69.7</td><td><strong>70.8</strong></td></tr>
    <tr><td>MultiNLI</td><td>74.6</td><td>76.2</td><td>77.8</td><td><strong>78.4</strong></td></tr>
    <tr><td>Living17</td><td>49.3</td><td>54.7</td><td>56.1</td><td><strong>59.2</strong></td></tr>
    <tr><td>NICO++</td><td>59.3</td><td>62.4</td><td>64.7</td><td><strong>66.3</strong></td></tr>
    <tr><th>Average</th><td>73.0</td><td>77.1</td><td>83.9</td><td><strong>83.0</strong></td></tr>
  </table>
</details>

<h2>BibTeX</h2>
<pre>
@inproceedings{to2025dpe,
  title={Diverse Prototypical Ensembles Improve Robustness to Subpopulation Shift},
  author={To, Minh Nguyen Nhat and Wilson, Paul F R and Nguyen, Viet and Harmanani, Mohamed and Cooper, Michael and
          Fooladgar, Fahimeh and Abolmaesumi, Purang and Mousavi, Parvin and Krishnan, Rahul},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2025}
}
</pre>

</body>
</html>
